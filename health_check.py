#!/usr/bin/env python3
"""
Health Check Script for Multi-Model AI Assistant with TinyLlama
Verifies all components are working correctly
"""

import os
import sys
import sqlite3
from pathlib import Path
import requests
from dotenv import load_dotenv

def print_header(title):
    """Print a formatted header"""
    print("\n" + "="*50)
    print(f" {title}")
    print("="*50)

def check_files():
    """Check if all required files exist"""
    print_header("üìÅ FILE SYSTEM CHECK")
    
    required_files = [
        'app.py',
        'requirements.txt',
        'templates/multi_model_chat.html',
        '.env'
    ]
    
    all_good = True
    for file in required_files:
        if Path(file).exists():
            print(f"‚úÖ {file}")
        else:
            print(f"‚ùå {file} - MISSING")
            all_good = False
    
    # Check model cache directory
    models_dir = Path('./models')
    if models_dir.exists():
        print(f"‚úÖ ./models/ (cache directory)")
    else:
        print(f"‚ÑπÔ∏è  ./models/ - Will be created on first run")
    
    return all_good

def check_environment():
    """Check environment variables"""
    print_header("üîß ENVIRONMENT CHECK")
    
    load_dotenv()
    
    secret_key = os.getenv('FLASK_SECRET_KEY')
    
    if secret_key:
        print("‚úÖ FLASK_SECRET_KEY: Set")
    else:
        print("‚ùå FLASK_SECRET_KEY: Missing")
    
    # Check TinyLlama settings
    device = os.getenv('TINYLLAMA_DEVICE', 'auto')
    max_length = os.getenv('TINYLLAMA_MAX_LENGTH', '512')
    
    print(f"‚ÑπÔ∏è  TINYLLAMA_DEVICE: {device}")
    print(f"‚ÑπÔ∏è  TINYLLAMA_MAX_LENGTH: {max_length}")
    
    return bool(secret_key)

def check_python_packages():
    """Check if all required packages are installed"""
    print_header("üì¶ PYTHON PACKAGES CHECK")
    
    packages = [
        'flask',
        'torch',
        'transformers',
        'sentence_transformers',
        'numpy',
        'faiss-cpu',
        'requests',
        'python-dotenv',
        'crawl4ai'
    ]
    
    all_installed = True
    for package in packages:
        try:
            if package == 'python-dotenv':
                import dotenv
                print(f"‚úÖ {package}")
            elif package == 'faiss-cpu':
                import faiss
                print(f"‚úÖ {package}")
            elif package == 'sentence_transformers':
                import sentence_transformers
                print(f"‚úÖ {package}")
            else:
                __import__(package.replace('-', '_'))
                print(f"‚úÖ {package}")
        except ImportError:
            print(f"‚ùå {package} - NOT INSTALLED")
            all_installed = False
    
    return all_installed

def check_pytorch_cuda():
    """Check PyTorch and CUDA setup"""
    print_header("üî• PYTORCH & CUDA CHECK")
    
    try:
        import torch
        print(f"‚úÖ PyTorch: Version {torch.__version__}")
        
        if torch.cuda.is_available():
            gpu_count = torch.cuda.device_count()
            gpu_name = torch.cuda.get_device_name(0)
            gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3
            print(f"üöÄ CUDA: Available with {gpu_count} GPU(s)")
            print(f"   GPU: {gpu_name} ({gpu_memory:.1f}GB)")
        else:
            print("üíª CUDA: Not available (will use CPU)")
        
        # Test basic tensor operations
        test_tensor = torch.randn(3, 3)
        if torch.cuda.is_available():
            test_tensor_gpu = test_tensor.cuda()
            print("‚úÖ GPU tensor operations: Working")
        
        print("‚úÖ PyTorch: Basic operations working")
        return True
        
    except ImportError:
        print("‚ùå PyTorch: Not installed")
        return False
    except Exception as e:
        print(f"‚ùå PyTorch: Error - {e}")
        return False

def check_tinyllama():
    """Check TinyLlama model availability"""
    print_header("üß† TINYLLAMA CHECK")
    
    try:
        from transformers import AutoTokenizer, AutoModelForCausalLM
        import torch
        
        model_name = "TinyLlama/TinyLlama-1.1B-Chat-v1.0"
        device = "cuda" if torch.cuda.is_available() else "cpu"
        
        print(f"üì• Checking TinyLlama model: {model_name}")
        print(f"üéØ Target device: {device}")
        
        # Check if model is cached
        cache_dir = Path('./models')
        if cache_dir.exists() and any(cache_dir.iterdir()):
            print("‚úÖ Model cache directory exists with content")
        else:
            print("‚ÑπÔ∏è  Model cache empty - will download on first run (~2GB)")
        
        # Try to load tokenizer (faster test)
        print("üî§ Testing tokenizer...")
        tokenizer = AutoTokenizer.from_pretrained(
            model_name,
            cache_dir='./models',
            trust_remote_code=True
        )
        print("‚úÖ Tokenizer: Loaded successfully")
        
        # Test basic tokenization
        test_text = "Hello, how are you?"
        tokens = tokenizer.encode(test_text)
        decoded = tokenizer.decode(tokens)
        print(f"‚úÖ Tokenizer test: '{test_text}' -> {len(tokens)} tokens")
        
        print("‚ÑπÔ∏è  Full model loading will happen on first app run")
        return True
        
    except ImportError as e:
        print(f"‚ùå TinyLlama dependencies missing: {e}")
        return False
    except Exception as e:
        print(f"‚ùå TinyLlama test failed: {e}")
        return False

def check_embeddings():
    """Check sentence transformers for embeddings"""
    print_header("üî§ EMBEDDINGS CHECK")
    
    try:
        from sentence_transformers import SentenceTransformer
        
        model_name = "all-MiniLM-L6-v2"
        print(f"üì• Loading embedding model: {model_name}")
        
        model = SentenceTransformer(model_name)
        
        # Test embedding generation
        test_sentence = "This is a test sentence."
        embedding = model.encode(test_sentence)
        
        print(f"‚úÖ Embedding model: Loaded successfully")
        print(f"‚úÖ Embedding dimension: {len(embedding)}")
        print(f"‚úÖ Test embedding: Generated for test sentence")
        
        return True
        
    except ImportError as e:
        print(f"‚ùå Sentence transformers missing: {e}")
        return False
    except Exception as e:
        print(f"‚ùå Embedding test failed: {e}")
        return False

def check_crawl4ai():
    """Check Crawl4AI and Playwright setup"""
    print_header("üåê WEB CRAWLING CHECK")
    
    try:
        from crawl4ai import AsyncWebCrawler
        print("‚úÖ Crawl4AI: Imported successfully")
        
        # Check if playwright browsers are installed
        try:
            import subprocess
            result = subprocess.run(['python', '-m', 'playwright', '--version'], 
                                  capture_output=True, text=True, timeout=10)
            if result.returncode == 0:
                print(f"‚úÖ Playwright: {result.stdout.strip()}")
            else:
                print("‚ö†Ô∏è  Playwright: Version check failed")
        except Exception:
            print("‚ö†Ô∏è  Playwright: Could not check version")
        
        print("‚úÖ Web crawling: Ready for auto-research")
        return True
            
    except ImportError as e:
        print(f"‚ùå Crawl4AI: Not available ({e})")
        print("   Install with: pip install crawl4ai")
        print("   Then run: python -m playwright install")
        return False
    except Exception as e:
        print(f"‚ùå Crawl4AI: Error ({e})")
        return False

def check_database():
    """Check database functionality"""
    print_header("üíæ DATABASE CHECK")
    
    try:
        # Test SQLite connection
        conn = sqlite3.connect(':memory:')
        cursor = conn.cursor()
        cursor.execute('SELECT sqlite_version()')
        version = cursor.fetchone()[0]
        conn.close()
        print(f"‚úÖ SQLite: Version {version}")
        
        # Check if main database exists
        if Path('chatbot_users.db').exists():
            print("‚úÖ User Database: Exists")
        else:
            print("‚ÑπÔ∏è  User Database: Will be created on first run")
        
        return True
        
    except Exception as e:
        print(f"‚ùå Database: Error - {e}")
        return False

def test_basic_functionality():
    """Test basic system functionality"""
    print_header("üß™ FUNCTIONALITY TEST")
    
    try:
        # Test imports from main app
        sys.path.insert(0, '.')
        
        print("Testing core components...")
        
        # Test database manager
        from app import DatabaseManager
        db = DatabaseManager(':memory:')
        print("‚úÖ DatabaseManager: OK")
        
        # Test emotion detector
        from app import EmotionDetector
        emotion_detector = EmotionDetector()
        result = emotion_detector.detect_emotion("I'm happy!")
        print(f"‚úÖ EmotionDetector: OK (detected: {result.emotion})")
        
        # Test model manager
        from app import AIModelManager
        model_manager = AIModelManager()
        models = model_manager.get_all_models()
        print(f"‚úÖ AIModelManager: OK ({len(models)} models)")
        
        # Test web crawler
        from app import SmartWebCrawler
        crawler = SmartWebCrawler()
        should_crawl = crawler.should_crawl_for_query("Tell me about Apple company")
        print(f"‚úÖ SmartWebCrawler: OK (would crawl: {should_crawl})")
        
        # Test TinyLlama manager (without loading full model)
        from app import TinyLlamaManager, TINYLLAMA_AVAILABLE
        if TINYLLAMA_AVAILABLE:
            print("‚úÖ TinyLlamaManager: Dependencies available")
        else:
            print("‚ö†Ô∏è  TinyLlamaManager: Dependencies missing")
        
        # Test embedding manager
        from app import LocalEmbeddingManager
        emb_manager = LocalEmbeddingManager()
        if emb_manager.available:
            test_emb = emb_manager.generate_embedding("test")
            print(f"‚úÖ LocalEmbeddingManager: OK (dim: {len(test_emb)})")
        else:
            print("‚ö†Ô∏è  LocalEmbeddingManager: Not available")
        
        return True
        
    except Exception as e:
        print(f"‚ùå Functionality Test: Error - {e}")
        return False

def run_full_health_check():
    """Run complete health check"""
    print("üîç MULTI-MODEL AI ASSISTANT HEALTH CHECK")
    print("üß† Verifying TinyLlama and all components...")
    
    checks = [
        ("Files", check_files),
        ("Environment", check_environment),
        ("Python Packages", check_python_packages),
        ("PyTorch & CUDA", check_pytorch_cuda),
        ("TinyLlama", check_tinyllama),
        ("Embeddings", check_embeddings),
        ("Crawl4AI", check_crawl4ai),
        ("Database", check_database),
        ("Functionality", test_basic_functionality)
    ]
    
    results = {}
    for name, check_func in checks:
        try:
            results[name] = check_func()
        except Exception as e:
            print(f"‚ùå {name}: Unexpected error - {e}")
            results[name] = False
    
    # Summary
    print_header("üìä HEALTH CHECK SUMMARY")
    
    passed = sum(results.values())
    total = len(results)
    
    for name, result in results.items():
        status = "‚úÖ PASS" if result else "‚ùå FAIL"
        print(f"{status} {name}")
    
    print(f"\nüéØ Overall: {passed}/{total} checks passed")
    
    if passed == total:
        print("\nüéâ ALL SYSTEMS GO!")
        print("Your Multi-Model AI Assistant with TinyLlama is ready!")
        print("\nüöÄ To start the assistant:")
        print("  python app.py")
        print("  Then open: http://localhost:5000")
        print("\nüåê Features ready:")
        print("  üß† TinyLlama running locally (no API keys needed!)")
        print("  üåê Auto-research enabled - ask about companies, news, anything!")
        print("  üîí Completely private - everything runs on your machine!")
        print("\n‚ö° First run will download TinyLlama model (~2GB)")
        print("üöÄ After that, everything runs instantly offline!")
    else:
        print(f"\n‚ö†Ô∏è  {total - passed} issues need attention")
        print("Please fix the failed checks above before running the assistant")
        
        if not results.get("PyTorch & CUDA"):
            print("\nüí° Fix PyTorch:")
            print("  pip install torch torchvision torchaudio")
            print("  Or for GPU: pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118")
        
        if not results.get("TinyLlama"):
            print("\nüí° Fix TinyLlama:")
            print("  pip install transformers sentence-transformers")
            
        if not results.get("Crawl4AI"):
            print("\nüí° Fix Crawl4AI:")
            print("  pip install crawl4ai")
            print("  python -m playwright install")
    
    return passed == total

if __name__ == "__main__":
    try:
        success = run_full_health_check()
        sys.exit(0 if success else 1)
    except KeyboardInterrupt:
        print("\n\n‚èπÔ∏è  Health check interrupted")
        sys.exit(1)
    except Exception as e:
        print(f"\n‚ùå Unexpected error: {e}")
        sys.exit(1)